Some directions:
- What's the difference between a "perfect" (e.g. very slow dynamic-
  programming-based) aligner and an off-the-shelf aligner using the
  same scoring scheme?
- What kinds of alignments fool the mapq function?
- What sort of learning scheme can be used to learn a mapq function
  from simulated data?
- Besides learning a ranking, can we learn probabilities?
- Is it too much to ask that we learn a ranking *and* a good set of
  probabilities in the same step? 
- What can we say about overfitting?
- What can we say about the relative merits of different learning
  schemes?
- What changes (w/r/t both Bayesian and learning approaches) when we're
  looking at different assays? 
- Use Python scipy.interpolate.bisplrep or scipy.interpolate.interp2d

Ideas for validation:
- Use a dataset that enriches for a subset of the genome, like a single
  chromosome.  Treat alignments to that chromosome as correct.
- Use a dataset with a short, non-repetitive spike-in like PhiX or lambda.
  Treat alignments to lambda/PhiX as correct.